# Visualizing and Examples of Time Series

```{r child = 'pre-chapter-script.Rmd'}
```

In this chapter, we discuss some basics of time series. A time series is a collection of data points that include a time component. The time component can either be regular, such as every hour or every day, or it can be irregular. The data can either be aggregated (such as the number of iPhones sold over in one month) or it can be sampled (such as the closing price of a stock). In either case, it may be important that the time period of aggregation or sampling be short enough to detect volatility or deviations from trends. 

Our point of view in this class is that we will want to create models that describe the time series. Typical components of a model will include the **trend** of the data over time, the **seasonality** of the data, and the **random component** of the data. One important difference between time series and many other types of data is that time series data is usually **not** independent. For example, knowledge of the value of the time series at one time interval gives us probabilistic information about the value of the time series at nearby time intervals. If you knew that the high temperature on January 20, 2022 in St Louis is going to be 3 degrees Fahrenheit, you would probably guess that the high temperature on January 21 2022 will also be below normal for that time of year.

## Examples

In this section, we introduce some of the examples that we will be working with thoughout the book. 

::: example
Our first example is closing stock market prices. The package `quantmod` allows you to download prices of stocks, as long as you know the abbreviation to look for. Let's see how to use it.

```{r eval=FALSE}
library(quantmod)
getSymbols("AAPL", from = "2016-01-01", to = "2021-01-01", warnings = FALSE)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(quantmod)
load("data/apple.rda")
```


The previous command creates an object called `AAPL` which contains the desired information. Let's look at it.

```{r}
head(AAPL)
```

Most of the variable names are self-explanatory, but `AAPL.Adjusted` is the adjusted closing price of Apple, taking into account stock splits and dividends. This is the value that we will most often work with. To plot the adjusted closing price, we use the base R command `plot`. 

```{r}
plot(AAPL$AAPL.Adjusted)
```

If we just eyeball this plot, it seems as if there is an upward trend in the price of Apple over the time period. If we were to subtract the overall trend, then the leftover error would not be independent. Days on which the stock is below the overall trend seem to be followed by more days on which the stock is below the trend, for example.  We will continue looking at this below.
:::

::: example
In this example, we look at temperature data. Much of the data in this book will be in the `tswrdata` package. You can install the package by typing `remotes::install_github(repo = "speegled/tswrdata")`. If you do not have the `remotes` package installed, you will first have to type `library(remotes)`. 

The data set we are interested in is the `monthly` global mean temperature data set. It can be loaded as follows.

```{r}
mm <- tswrdata::monthly
head(mm)
summary(mm)
```

This data gives the mean global temperature for each month from January 6, 1880 through December 6, 2016. The value is in terms of difference from the approximate series mean.

This data set is not in the form of a time series, so we will use `ggplot` to visualize. But first, we average the two different methods for creating the mean global temperature for the month.

```{r}
mm %>% 
  group_by(date) %>% 
  summarize(temp = mean(mean)) %>% 
  ggplot(aes(x = date, y = temp)) + 
    geom_line()
```

This time series appears to have a trend as well as possibly a seasonal component. Let's average all of the monthly data and see if there appear to be differences. 

```{r}
mm %>% 
  group_by(date) %>% 
  summarize(temp = mean(mean)) %>% 
  mutate(month = lubridate::month(date)) %>% 
  group_by(month) %>% 
  summarize(temp = mean(temp)) %>% 
  ggplot(aes(x = factor(month), y = temp)) + 
    geom_col() + 
  scale_x_discrete()
```

This is not the best way to find seasonal variation, but even still we see that there appear to be two peaks per year; in the fall and in the spring for global mean temperature. We will see better ways to see seasonality later in this chapter.
:::

::: example
In this example, we look at unemployment data from Maine. It can be found in `maine` in the `tswrdata` package.

```{r}
maine <- tswrdata::maine
str(maine)
```

We note that `maine` consists of a single variable, which is the unemployment rate in Maine. If we look at the help page, we see that is monthly data. We can convert the data into a time series, indicating the start date and that it is monthly, as follows. Note how the plot improves.

```{r}
plot(maine$unemploy)
maine$unemploy <- ts(maine$unemploy, start = c(1996, 1), frequency = 12)
plot(maine$unemploy)
```

There are two R functions that we can use with time series, `aggregate` and `cycle`. The function `aggregate` performs calculations over seasons as defined by frequency. For example, if we want to compute the mean unemployment rate for each year over the time presented in the time series, then we could use

```{r}
aggregate(maine$unemploy, FUN  = mean)
```

Another function that we can use is `cycle`. This goes through the time series and assigns seasons to the time series.

```{r}
cycle(maine$unemploy)
maine$season <- factor(cycle(maine$unemploy))
ggplot(maine, aes(season, unemploy)) + 
  geom_boxplot(outlier.size = -1) + 
  geom_jitter(height = 0, width = 0.2, alpha = .5)
```
:::

## Decomposing time series

In this section, we look at estimating the trend, seasonal and random component of various time series. There are several ways of doing this, but we start with simple things that are easy to understand. We start with some notation and definitions.

::: definition
One additive decomposition model that we will be considering in this section is given by
\[
x_t = m_t + s_t + z_t
\]
where $x_t$ is the time series, $m_t$ is the trend, $s_t$ is the seasonal variation and $z_t$ is the random component. Recall that $z_t$ is **not** assumed to be independent in this book!

A multiplicative decomposition model for time series is 
\[
x_t = m_t s_t z_t
\]
where the components are multiplied together rather than added.
:::

::: {.example #exm:decomposeexample}
Consider the monthly global temperature data. One way to estimate the trend $m_t$ is to take a weighted average of the nearby values. Since the number of months in each season is even (12), we use the following formula:

\[
\hat m_t = \frac{\frac 12 x_{t - 6} + x_{t - 5} + \cdots + x_t + \cdots + x_{t + 5} + \frac 12 x_{t + 6}}{12}
\]

The reason we divide $x_{t - 6}$ and $x_{t + 6}$ by 1/2 is that they each refer to the same month. For example, if $t = 7$ (so that we are in July), then $t - 6 = 1$, which is January, and $t + 6 = 13$, which is also January. We don't want the two Januaries to count twice, so we just average the 2. The R command that does this is `filter` (or `convolve`). The way `filter` takes arguments `x`, which is the data, `filter`, which is the weights that we use for the weighted average of values, and `sides = 2` centers the filter like we want. Note that `filter` is hidden by `dplyr` so we have to specify to R that we want to use `stats::filter` rather than `dplyr::filter`. 

```{r}
mm <- tswrdata::monthly
filter <- c(1/24, rep(1/12, 11), 1/24)
sum(filter) #sums to 1
mm <- mm %>% 
  group_by(date) %>% 
  summarize(temp = mean(mean)) %>% 
  mutate(trend = stats::filter(temp, filter = filter))
```

We see that there are missing values at the beginning (and end). That is because our filter tries to average things that extend beyond the beginning (and end) of the time series. There are only a few missing values, but it can be very annoying because many times the most recent values are exactly the ones that you care most about.

Let's visualize it:

```{r}
ggplot(mm, aes(x = date, y = temp)) + 
  geom_point(alpha = .1) + 
  geom_line(mapping = aes(y = trend))
```

That is still really variable!

Once we have estimated $\hat m_t$, we then estimate $s_t$ by computing
\[
\hat s_t = x_t - \hat m_t
\]
and **averaging** over all years of observation. In this way, we get a single number for each season that we have.

```{r}
mm %>% 
  mutate(season = temp - trend, 
         month = lubridate::month(date)) %>% 
  group_by(month) %>% 
  summarize(season = mean(season, na.rm = T)) %>% 
  ggplot(aes(x = month, y = season)) + 
  geom_line()
  
```

This corresponds with original thought that there are two peaks per year in mean temperature. Finally, to get the random component, we would compute

\[
\hat z_t = x_t - \hat m_t - \hat_s_t
\]

```{r}
mm <- mm %>% mutate(season = temp - trend, 
         month = lubridate::month(date)) %>% 
  group_by(month) %>% 
  mutate(season = mean(season, na.rm = T)) %>% 
  mutate(random = temp - trend - season) %>% 
  ungroup()

library(tidyr) #for pivot_longer
mm %>% 
  pivot_longer(cols = c(temp, trend, season, random)) %>% 
  mutate(name = factor(name, levels = c("temp", "trend", "season", "random"))) %>% 
  ggplot(aes(x = date, y = value)) + 
  geom_line() + 
  facet_grid(name~., scales = "free_y")
```


There is a built-in R function that does all of this for us, called `decompose`. It doesn't give exactly the same answers because it centers the season values by subtracting the mean of all of the season values.

```{r}
mod <- decompose(ts(mm$temp, start = c(1880, 1), frequency = 12))
mod$seasonal[1:12]
mm$season[1:12]
mod$seasonal[1:12] - mean(mod$seasonal[1:12]) #these match perfectly
plot(mod)
```
:::

It is also possible to use different filters than the default in `decompose`. The default filter simply averages all of the values in the season that is closest to the current value. Its primary use is for removing seasonal variation in a time series. One downside is the sharp cut-offs at the ends of the filter, so that a value either contributes quite a bit to the moving average, or it contributes nothing. 

An alternative is to use the coefficients in the expansion of $\bigl(\frac 12x + \frac 12y\bigr)^{2q}$. For example, when $q = 1$, we get coefficients $(1/4, 1/2, 1/4)$, which corresponds to $\frac 14 x^2 + \frac 12 xy + \frac 14 y^2$. The general form for the coefficients is

\[
\frac 1{2^{2q}} {2q \choose k} \qquad 0 \le k \le 2q
\]

Let's see what the trend of Apple stock would look like if we use this filter. For some purposes, it is easier to have the stock price in tidy format rather than from `quantmod`. To do this, we use `tidyquant`, which can be installed via `devtools::install_github("business-science/tidyquant")`

```{r}
AAPL <- tidyquant::tq_get("AAPL")
q <- 12 #this is 2q
AAPL %>% 
  mutate(trend = stats::filter(adjusted, filter = choose(q, 0:q)/2^(q), sides = 2)) %>% 
  ggplot(aes(x = date)) + 
    geom_point(mapping = aes(y = adjusted), color = "pink") +
   geom_line(mapping = aes(y = trend), color = "red")
```

```{r echo = FALSE, eval = FALSE}
load("data/tidyapple.rda")
q <- 12 #this is 2q
AAPL %>% 
  mutate(trend = stats::filter(adjusted, filter = choose(q, 0:q)/2^(q), sides = 2)) %>% 
  ggplot(aes(x = date)) + 
    geom_point(mapping = aes(y = adjusted), color = "pink") +
   geom_line(mapping = aes(y = trend), color = "red")
```

::: tryit
Change the value of $q$ in the above code and see how it affects the plot. Which value do you like the best?
:::


## Exercises

::: exercise
Consider the `blackberry` data in the `tswrdata` package. Create an additive decomposition into trend, season and random components of the number of units of handeld blackberries sold using 4 cycles per season. Plot it and comment on the random component. 
:::

::: exercise
Consider the unemployment data `maine` in the `tswrdata` package. Create a plot using `ggplot` of the unemployment, trend, seasonal and random components as was done in Example \@ref(exm:decomposeexample).
:::


::: exercise
Consider the `stltemp` data in the `tswrdata` package. Plot the maximum temperature from Lambert Airport Station from January 1, 1980 through December 31, 1999. 

Decompose the time series into a trend, season and random component and plot each of the three components. Use a seasonal component of 365 days.
:::

::: exercise
Consider the `vaccines` data in the `tswrdata` package. Create a multiplicative decomposition into trend, season and random components of the number of doses of vaccine given in missouri. Plot it and comment. 
:::

